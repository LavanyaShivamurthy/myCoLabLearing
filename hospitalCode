import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.multioutput import MultiOutputClassifier
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

# Let's first define helper functions
def load_and_preprocess_data(data_path):
    """
    Load the hospital network data and perform initial preprocessing
    """
    # Load the data
    df = pd.read_csv(data_path)
    
    # Display basic information
    print(f"Dataset shape: {df.shape}")
    print(f"Features available: {df.columns.tolist()}")
    
    # Check for missing values
    missing_values = df.isnull().sum()
    print(f"Missing values per column:\n{missing_values[missing_values > 0]}")
    
    # Drop rows with missing values or impute them based on your strategy
    df = df.dropna()
    
    return df

def extract_features(df):
    """
    Extract and engineer features from network data
    """
    # Create features specific to hospital network traffic
    
    # Time-based features
    df['time_delta_ms'] = df['frame.time_delta'].astype(float) * 1000  # Convert to milliseconds
    df['packet_size'] = df['frame.len'].astype(float)
    
    # TCP flag-based features
    flag_columns = [col for col in df.columns if 'tcp.flags' in col]
    for col in flag_columns:
        df[col] = df[col].fillna(0).astype(int)
    
    # Create aggregated features
    if 'tcp.len' in df.columns:
        df['tcp_payload_ratio'] = df['tcp.len'] / df['frame.len']
    
    # MQTT specific features (if available)
    mqtt_columns = [col for col in df.columns if 'mqtt' in col]
    if mqtt_columns:
        # Convert categorical MQTT fields to numeric
        for col in mqtt_columns:
            if df[col].dtype == 'object':
                df[col] = pd.factorize(df[col])[0]
    
    # Source/destination features
    if 'ip.src' in df.columns and 'ip.dst' in df.columns:
        # Create categorical encodings for source and destination IPs
        df['src_ip_encoded'] = pd.factorize(df['ip.src'])[0]
        df['dst_ip_encoded'] = pd.factorize(df['ip.dst'])[0]
    
    # Port-based features
    if 'tcp.srcport' in df.columns and 'tcp.dstport' in df.columns:
        # Known medical device ports (example - replace with actual ports)
        medical_ports = [1234, 5678, 9012]  # Replace with actual medical device ports
        df['is_medical_src_port'] = df['tcp.srcport'].isin(medical_ports).astype(int)
        df['is_medical_dst_port'] = df['tcp.dstport'].isin(medical_ports).astype(int)
    
    # Select numerical features for the model
    numerical_features = ['time_delta_ms', 'packet_size', 'src_ip_encoded', 'dst_ip_encoded']
    numerical_features.extend([col for col in flag_columns if col in df.columns])
    
    if 'tcp_payload_ratio' in df.columns:
        numerical_features.append('tcp_payload_ratio')
    
    if 'is_medical_src_port' in df.columns:
        numerical_features.extend(['is_medical_src_port', 'is_medical_dst_port'])
    
    # Add additional MQTT features if available
    numerical_features.extend([col for col in mqtt_columns if col in df.columns])
    
    # Filter to include only available columns
    numerical_features = [col for col in numerical_features if col in df.columns]
    
    print(f"Selected features: {numerical_features}")
    
    return df, numerical_features

def create_target_variables(df, emergency_keywords, important_keywords):
    """
    Create binary target variables for the multitask classification
    emergency: 1 if emergency, 0 if not
    important: 1 if important, 0 if not
    """
    # This is a simplified approach - in a real scenario, you would have labeled data
    # or more sophisticated rules to determine emergency and importance
    
    # Example: Check if certain keywords or patterns appear in destination IP or ports
    df['emergency'] = 0
    df['important'] = 0
    
    # Example rule for emergency (based on destination port or IP pattern)
    if 'tcp.dstport' in df.columns:
        df.loc[df['tcp.dstport'].isin(emergency_keywords), 'emergency'] = 1
    
    # Example rule for importance (based on destination port or payload size)
    if 'tcp.len' in df.columns:
        df.loc[df['tcp.len'] > important_keywords, 'important'] = 1
    
    # Count instances of each class
    emergency_count = df['emergency'].sum()
    important_count = df['important'].sum()
    
    print(f"Emergency packets: {emergency_count} ({emergency_count/len(df)*100:.2f}%)")
    print(f"Important packets: {important_count} ({important_count/len(df)*100:.2f}%)")
    
    # Create the 4-class priority label (for reference)
    df['priority_class'] = 4  # Default: Not Emergency and Not Important (lowest priority)
    df.loc[(df['emergency'] == 1) & (df['important'] == 1), 'priority_class'] = 1  # Emergency and Important
    df.loc[(df['emergency'] == 1) & (df['important'] == 0), 'priority_class'] = 2  # Emergency but Not Important
    df.loc[(df['emergency'] == 0) & (df['important'] == 1), 'priority_class'] = 3  # Not Emergency but Important
    
    # Count instances of each priority class
    for i in range(1, 5):
        count = (df['priority_class'] == i).sum()
        print(f"Priority class {i}: {count} ({count/len(df)*100:.2f}%)")
    
    return df

def train_multitask_model(X, y):
    """
    Train a multitask classification model to predict emergency and importance
    """
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y['emergency'])
    
    print(f"Training set size: {X_train.shape}")
    print(f"Testing set size: {X_test.shape}")
    
    # Create preprocessing pipeline
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), list(range(X.shape[1])))
        ])
    
    # Create and train the model
    # We'll use XGBoost for the base classifier in a MultiOutputClassifier
    model = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', MultiOutputClassifier(XGBClassifier(
            n_estimators=100,
            learning_rate=0.05,
            max_depth=4,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42
        )))
    ])
    
    print("Training the model...")
    model.fit(X_train, y_train)
    print("Training completed.")
    
    return model, X_train, X_test, y_train, y_test

def evaluate_model(model, X_test, y_test):
    """
    Evaluate the model performance
    """
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Convert predictions to DataFrame
    y_pred_df = pd.DataFrame(y_pred, columns=y_test.columns)
    
    # Evaluate each task separately
    for task in y_test.columns:
        print(f"\nEvaluation for {task} prediction:")
        print(classification_report(y_test[task], y_pred_df[task]))
        
        # Create confusion matrix
        cm = confusion_matrix(y_test[task], y_pred_df[task])
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not ' + task.title(), task.title()], 
                   yticklabels=['Not ' + task.title(), task.title()])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title(f'Confusion Matrix for {task.title()} Prediction')
        plt.show()
    
    # Calculate the 4-class accuracy
    y_test['pred_emergency'] = y_pred_df['emergency']
    y_test['pred_important'] = y_pred_df['important']
    
    y_test['true_priority'] = 4  # Default: Not Emergency and Not Important
    y_test.loc[(y_test['emergency'] == 1) & (y_test['important'] == 1), 'true_priority'] = 1
    y_test.loc[(y_test['emergency'] == 1) & (y_test['important'] == 0), 'true_priority'] = 2
    y_test.loc[(y_test['emergency'] == 0) & (y_test['important'] == 1), 'true_priority'] = 3
    
    y_test['pred_priority'] = 4  # Default: Not Emergency and Not Important
    y_test.loc[(y_test['pred_emergency'] == 1) & (y_test['pred_important'] == 1), 'pred_priority'] = 1
    y_test.loc[(y_test['pred_emergency'] == 1) & (y_test['pred_important'] == 0), 'pred_priority'] = 2
    y_test.loc[(y_test['pred_emergency'] == 0) & (y_test['pred_important'] == 1), 'pred_priority'] = 3
    
    # Calculate accuracy for the 4-class problem
    priority_accuracy = accuracy_score(y_test['true_priority'], y_test['pred_priority'])
    print(f"\nOverall 4-class priority accuracy: {priority_accuracy:.4f}")
    
    # Create confusion matrix for the 4-class problem
    cm = confusion_matrix(y_test['true_priority'], y_test['pred_priority'])
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
               xticklabels=['Priority 1', 'Priority 2', 'Priority 3', 'Priority 4'],
               yticklabels=['Priority 1', 'Priority 2', 'Priority 3', 'Priority 4'])
    plt.xlabel('Predicted Priority')
    plt.ylabel('Actual Priority')
    plt.title('Confusion Matrix for 4-Class Priority Prediction')
    plt.show()
    
    return y_test

def predict_new_traffic(model, new_data, numerical_features):
    """
    Use the trained model to predict priority for new network traffic
    """
    # Preprocess the new data
    X_new = new_data[numerical_features]
    
    # Make predictions
    predictions = model.predict(X_new)
    
    # Convert predictions to DataFrame
    pred_df = pd.DataFrame(predictions, columns=['emergency', 'important'])
    
    # Map to priority classes
    pred_df['priority_class'] = 4  # Default: Not Emergency and Not Important
    pred_df.loc[(pred_df['emergency'] == 1) & (pred_df['important'] == 1), 'priority_class'] = 1
    pred_df.loc[(pred_df['emergency'] == 1) & (pred_df['important'] == 0), 'priority_class'] = 2
    pred_df.loc[(pred_df['emergency'] == 0) & (pred_df['important'] == 1), 'priority_class'] = 3
    
    # Map to priority labels
    priority_labels = {
        1: "Emergency and Important (highest priority)",
        2: "Emergency but Not Important",
        3: "Not Emergency but Important",
        4: "Not Emergency and Not Important (lowest priority)"
    }
    
    pred_df['priority_label'] = pred_df['priority_class'].map(priority_labels)
    
    # Combine with original data
    result = pd.concat([new_data.reset_index(drop=True), pred_df], axis=1)
    
    return result

# Main execution
def main():
    # Sample execution - replace with your actual data path
    data_path = "hospital_network_data.csv"
    
    try:
        # Step 1: Load and preprocess data
        print("Step 1: Loading and preprocessing data...")
        df = load_and_preprocess_data(data_path)
        
        # Step 2: Extract features
        print("\nStep 2: Extracting features...")
        df, numerical_features = extract_features(df)
        
        # Step 3: Create target variables (in a real scenario, you would have labeled data)
        print("\nStep 3: Creating target variables...")
        # For demonstration, we're using example keywords/thresholds
        # Replace these with actual criteria for your hospital network 
        emergency_port_numbers = [80, 443, 8080]  # Example emergency ports
        important_payload_size = 1000  # Example importance threshold based on packet size
        df = create_target_variables(df, emergency_port_numbers, important_payload_size)
        
        # Step 4: Train the model
        print("\nStep 4: Training the multitask model...")
        X = df[numerical_features]
        y = df[['emergency', 'important']]
        model, X_train, X_test, y_train, y_test = train_multitask_model(X, y)
        
        # Step 5: Evaluate the model
        print("\nStep 5: Evaluating the model...")
        evaluation_results = evaluate_model(model, X_test, y_test)
        
        # Step 6: Make predictions on new data (in a real scenario)
        print("\nStep 6: Demonstrating prediction on new data...")
        # For demonstration, we'll use a small subset of the test data as "new" data
        new_data = X_test.iloc[:5].copy()
        predictions = predict_new_traffic(model, new_data, numerical_features)
        print("\nSample predictions:")
        print(predictions[['priority_class', 'priority_label']])
        
        print("\nModel training and evaluation completed successfully.")
        
    except Exception as e:
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()
